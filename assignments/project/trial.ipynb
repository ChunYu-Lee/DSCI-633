{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title                location  \\\n",
      "0               Architect (Middleware - MQ) - Kuwait                KW, KU,    \n",
      "1  Interviewing Now for Sales Rep Positions -- wi...  US, TX, Corpus Christi   \n",
      "2  Process Controls Staff Engineer - Foxboro I/A ...   US, TX, USA Southwest   \n",
      "3  Experienced Telemarketer Wanted - Digital Solu...               AU, NSW,    \n",
      "4                            Senior Network Engineer         GB, ENG, London   \n",
      "\n",
      "                                         description  \\\n",
      "0  On behalf of our client, a well known multinat...   \n",
      "1  We are Argenta Field Solutions, a rapidly expa...   \n",
      "2  Experienced Process Controls Staff Engineer is...   \n",
      "3  If you have a passion for people and love to s...   \n",
      "4  As the successful Senior Network Engineer you ...   \n",
      "\n",
      "                                        requirements  telecommuting  \\\n",
      "0  -Working technical knowledge of IT systems and...              0   \n",
      "1                                             #NAME?              0   \n",
      "2  At least 10 years of degreed professional expe...              0   \n",
      "3  Responsibilities - Prospecting, following up a...              0   \n",
      "4  Essential skills:•Juniper switching/routing/se...              0   \n",
      "\n",
      "   has_company_logo  has_questions  fraudulent  \n",
      "0                 1              0           0  \n",
      "1                 1              0           0  \n",
      "2                 0              0           0  \n",
      "3                 1              0           0  \n",
      "4                 1              0           0  \n"
     ]
    }
   ],
   "source": [
    "# 8940 cases, fraud 456 cases -->imbalance data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "pd.set_option('max_columns',None)\n",
    "data = pd.read_csv(\"../data/job_train.csv\")\n",
    "\n",
    "# get the column: description\n",
    "col = data[\"description\"]\n",
    "target = data[\"fraudulent\"]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "split_point = int(0.8 * len(target))\n",
    "X_train = col.iloc[:split_point]\n",
    "X_test = col.iloc[split_point:]\n",
    "y_train = target.iloc[:split_point]\n",
    "y_test = target.iloc[split_point:]\n",
    "\n",
    "# clear the null value in the target col\n",
    "col.fillna(' ', inplace = True)\n",
    "col.isnull().sum()\n",
    "\n",
    "#check the null value in the data set\n",
    "# data.isnull().sum()\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "# print(X_train_counts.shape)\n",
    "\n",
    "# count_vect.vocabulary_.get(\"1\")\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# print(X_train_tf.shape)\n",
    "\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf,y_train)\n",
    "\n",
    "\n",
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "# print(X_new_counts)\n",
    "# print(X_new_tfidf)\n",
    "# for x, y in zip(X_test, predicted):\n",
    "#     if (y==1):\n",
    "#         print(x,y)\n",
    "\n",
    "\n",
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "# print(df)\n",
    "df_majority = df[df.fraudulent==0]\n",
    "df_minority = df[df.fraudulent==1]\n",
    "# print(df_majority)\n",
    "# print(df_minority)\n",
    "\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, replace=False,    # sample without replacement\n",
    "n_samples=len(df_minority)  # to match minority class\n",
    ",random_state=1234) # reproducible results\n",
    "\n",
    "# print(df_majority_downsampled)\n",
    "\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "df_downsampled = df_downsampled.sample(frac=1)\n",
    "df_x = df_downsampled.drop(['fraudulent'], axis=1)\n",
    "df_y = df_downsampled[\"fraudulent\"]\n",
    "\n",
    "\n",
    "# print(df_downsampled)\n",
    "# print(df_x)\n",
    "# print(df_y)\n",
    "# print(col)\n",
    "\n",
    "preprocessor = TfidfVectorizer(stop_words='english', norm='l2', use_idf=False, smooth_idf=False)\n",
    "XX = preprocessor.fit_transform(df_x[\"description\"])\n",
    "\n",
    "# print(XX)\n",
    "# print(X_train.shape,XX.shape,df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  start_time = time.time()\n",
    "#     while time.time() - start_time < 25 * 60:\n",
    "#         # Iteration of model training or hyperparameter tuning\n",
    "#     return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title              location  \\\n",
      "11                                           Dispatcher    US, OH, Cincinnati   \n",
      "31                            Mobile Developer-Back End       US, WA, Seattle   \n",
      "37                                 Administrative Clerk                US, ,    \n",
      "88                               Junior Project Manager     ES, CT, Barcelona   \n",
      "102   Data Center Migration App Lead for FULL-TIME O...    US, PA, Harrisburg   \n",
      "...                                                 ...                   ...   \n",
      "8883                        Military Benefits Counselor         US, , chicago   \n",
      "8886                       Cruise Staff Wanted *URGENT*  US, NY, NEWYORK CITY   \n",
      "8897             Account Sales Managers $80-$130,000/yr     US, NY, Rochester   \n",
      "8907                     Research Engineer Data Science     US, CA, San Mateo   \n",
      "8938                           Administrative Assistant     US, CA, Santa Ana   \n",
      "\n",
      "                                            description  \\\n",
      "11    Organizes item orders by editing for price, pr...   \n",
      "31    Managing over 200 TB of data, including 34 tri...   \n",
      "37    processing letters, proposals and contracts in...   \n",
      "88                                Descripción de prueba   \n",
      "102   Data Center Migration Application Lead / Archi...   \n",
      "...                                                 ...   \n",
      "8883  FOR MILITARY ONLYIf you can call present and p...   \n",
      "8886  6* Ultra Luxury American Cruise Company is urg...   \n",
      "8897  We have aggressive growth plans in place for t...   \n",
      "8907  Qualified candidates are encouraged to apply d...   \n",
      "8938   In addition to clerical and administrative du...   \n",
      "\n",
      "                                           requirements  telecommuting  \\\n",
      "11     Documentation Skills, Data Entry Skills, Tele...              0   \n",
      "31    What You Offer:Experience in writing clean and...              0   \n",
      "37    prior hospitality experience a pluscomputer pr...              0   \n",
      "88                                Descripción de prueba              0   \n",
      "102                                                 NaN              0   \n",
      "...                                                 ...            ...   \n",
      "8883  must be:Active duty or veteran servicememberha...              1   \n",
      "8886  Certification &amp; Experience: Previous exper...              0   \n",
      "8897  Experience and Skills  Required- Minimum of 3 ...              0   \n",
      "8907  Position requirements: Quickly learning new ar...              0   \n",
      "8938                                                NaN              0   \n",
      "\n",
      "      has_company_logo  has_questions  fraudulent  \n",
      "11                   1              1           1  \n",
      "31                   1              0           1  \n",
      "37                   0              0           1  \n",
      "88                   0              0           1  \n",
      "102                  0              0           1  \n",
      "...                ...            ...         ...  \n",
      "8883                 1              1           1  \n",
      "8886                 0              1           1  \n",
      "8897                 1              0           1  \n",
      "8907                 1              1           1  \n",
      "8938                 0              0           1  \n",
      "\n",
      "[456 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data[data.fraudulent==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-51fed7ce883c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Predict probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RIT_Class/DSCI-633/assignments/assignment2/my_DT.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         if (\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from assignment2.my_DT import my_DT\n",
    "# from assignment8.my_evaluation import my_evaluation\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #  Load training data\n",
    "    data = pd.read_csv(\"../data/job_train.csv\")\n",
    "    # Separate independent variables and dependent variables [\"title\",\"location\",\"description\",\"requirements\",\"telecommuting\",\"has_company_logo\",\"has_questions\"]\n",
    "    target = [\"telecommuting\",\"has_company_logo\",\"has_questions\", \"fraudulent\"]\n",
    "    independent = [\"telecommuting\",\"has_company_logo\",\"has_questions\"]\n",
    "    \n",
    "    data_x = data[target]\n",
    "    split_point = int(0.8 * len(data))\n",
    "    X_train = data_x.iloc[:split_point]\n",
    "    X_test = data_x.iloc[split_point:]\n",
    "    y_train = data_x.iloc[:split_point]\n",
    "    y_test = data_x.iloc[split_point:]\n",
    "    \n",
    "    \n",
    "    X = X_train[independent]\n",
    "    y = y_train[\"fraudulent\"]\n",
    "    # Train model\n",
    "    clf = my_DT()\n",
    "    clf.fit(X,y)\n",
    "    # Load testing data\n",
    "#     data_test = pd.read_csv(\"../data/Iris_test.csv\")\n",
    "    X_test = X_test[independent]\n",
    "    # Predict\n",
    "    predictions = clf.predict(X_test)\n",
    "    # Predict probabilities\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    # Print results\n",
    "    for i,pred in enumerate(predictions):\n",
    "        print(\"%s\\t%f\" %(pred, probs[pred][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.500000\n",
      "0\t0.500000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-59133ab87b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\t%f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils import resample\n",
    "\n",
    "data = pd.read_csv(\"../data/job_train.csv\")\n",
    "# Separate independent variables and dependent variables [\"title\",\"location\",\"description\",\"requirements\",\"telecommuting\",\"has_company_logo\",\"has_questions\"]\n",
    "target = [\"telecommuting\",\"has_company_logo\",\"has_questions\", \"fraudulent\"]\n",
    "independent = [\"telecommuting\",\"has_company_logo\",\"has_questions\"]\n",
    "\n",
    "\n",
    "split_point = int(0.8 * len(data))\n",
    "X_train = data.iloc[:split_point]\n",
    "X_test = data.iloc[split_point:]\n",
    "y_train = data.iloc[:split_point]\n",
    "y_test = data.iloc[split_point:]\n",
    "\n",
    "df = pd.concat([X_train], axis=1)\n",
    "df_majority = df[df.fraudulent==0]\n",
    "df_minority = df[df.fraudulent==1]\n",
    "df_minority_oversampled = resample(df_minority, replace=True,n_samples=len(df_majority),random_state=1234)\n",
    "df_oversampled = pd.concat([df_minority_oversampled, df_majority])\n",
    "df_oversampled = df_oversampled.sample(frac=1)\n",
    "df_x = df_oversampled.drop([\"fraudulent\"], axis=1)\n",
    "df_y = df_oversampled[\"fraudulent\"]\n",
    "\n",
    "X = df_x[independent]\n",
    "y = df_y\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,y)\n",
    "\n",
    "X_t = df_x[independent]\n",
    "# Predict\n",
    "predictions = clf.predict(X_t)\n",
    "# # # Predict probabilities\n",
    "probs = clf.predict_proba(X_t)\n",
    "for i,pred in enumerate(predictions):\n",
    "    print(\"%s\\t%f\" %(pred, probs[pred][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a03f24985a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requirements\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df = pd.concat([data[\"requirements\"],t],axis = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# length = len(data[\"requirements\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "t = pd.DataFrame(len(data[\"requirements\"]))\n",
    "# df = pd.concat([data[\"requirements\"],t],axis = 1)\n",
    "# length = len(data[\"requirements\"])\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.696629\n",
      "1.0761630495389303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as random\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from assignment8.my_evaluation import my_evaluation\n",
    "\n",
    "\n",
    "class my_model():\n",
    "    def fit(self, X, y):\n",
    "        # do not exceed 29 mins\n",
    "        df = pd.concat([X, y], axis=1)\n",
    "        df_majority = df[df.fraudulent==0]\n",
    "        df_minority = df[df.fraudulent==1]\n",
    "        df_minority_oversampled = resample(df_minority, replace=True,n_samples=len(df_majority),random_state=1234)\n",
    "        df_oversampled = pd.concat([df_minority_oversampled, df_majority])\n",
    "        df_oversampled = df_oversampled.sample(frac=1)\n",
    "        df_x = df_oversampled.drop(['fraudulent'], axis=1)\n",
    "        df_y = df_oversampled[\"fraudulent\"]\n",
    "        \n",
    "        self.preprocessor = TfidfVectorizer(stop_words='english', norm='l2', use_idf=False, smooth_idf=False)\n",
    "        XX = self.preprocessor.fit_transform(df_x[\"description\"]+df_x[\"requirements\"])\n",
    "        \n",
    "        parameters = {'loss':('epsilon_insensitive', 'hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron','squared_loss', 'huber', 'squared_epsilon_insensitive' ), 'class_weight': ('balanced', 'weight'),'alpha': (1e-1, 1e-4)}\n",
    "        self.clf = SGDClassifier( loss='epsilon_insensitive',class_weight=\"balanced\", alpha = 0.0001)\n",
    "        self.gs_clf = GridSearchCV(self.clf, parameters, cv=5, n_jobs=-1).fit(XX, df_y)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        # remember to apply the same preprocessing in fit() on test data before making predictions\n",
    "        XX = self.preprocessor.transform(X[\"description\"]+X[\"requirements\"]) #X[\"description\"] X[\"requirements\"]\n",
    "        predictions = self.gs_clf.predict(XX)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    y = data[\"fraudulent\"]\n",
    "    X = data.drop(['fraudulent'], axis=1)\n",
    "    split_point = int(0.8 * len(y))\n",
    "    X_train = X.iloc[:split_point]\n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    y_test = y.iloc[split_point:]\n",
    "    clf = my_model()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    eval = my_evaluation(predictions, y_test)\n",
    "    f1 = eval.f1(target=1)\n",
    "    return f1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"../data/job_train.csv\")\n",
    "    # Replace missing values with empty strings\n",
    "    data = data.fillna(\"\")\n",
    "    f1 = test(data)\n",
    "    print(\"F1 score: %f\" % f1)\n",
    "    runtime = (time.time() - start) / 60.0\n",
    "    print(runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
